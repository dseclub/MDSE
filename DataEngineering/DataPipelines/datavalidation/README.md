# Data Validation frameworks

**Apache Hudi** brings stream processing to big data, providing fresh data while being an order of magnitude efficient over traditional batch processing. Features:

- Upsert support with fast, pluggable indexing.

- Atomically publish data with rollback support.

- Snapshot isolation between writer & queries.

- Savepoints for data recovery.

- Manages file sizes, layout using statistics.

- Async compaction of row & columnar data.

- Timeline metadata to track lineage.

- Optimize data lake layout with clustering.

https://github.com/apache/hudi

https://hudi.apache.org/


------------------

**Delta Lake** is a storage layer that brings scalable, ACID transactions to Apache Spark and other big-data engines.

https://github.com/delta-io/delta




------------------


**Great Expectations** is a python-based open-source data validation and documentation framework.

https://github.com/great-expectations/great_expectations
